{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # (Image References)\n",
    "\n",
    "# Udacity Deep Learning NanoDegree - Project 1: Navigation\n",
    "\n",
    "Darren Ewaniuk\n",
    "\n",
    "***\n",
    "### Learning Algorithm\n",
    "\n",
    "The learning algorithm for training an agent in this project is built upon the Q-learning algorithm with a neural network of two fully connected hidden layers approximating the Q-value function. The neural network architecture is set out in `model.py` and the agent behavior is set out in `dqn_agent.py`.\n",
    "\n",
    "***\n",
    "The steps of the learning process is: \n",
    "* For each episode, repeat:\n",
    "  * For each step, repeat : \n",
    "    * After observing a state at time t, agent takes (epsilon-greedy) action per current policy \n",
    "    * After taking action at time t, agent observes state and reward at t+1\n",
    "    * Agent then adds the \"SARS\" tuple to memory \n",
    "    * At every `UPDATE_EVERY` steps, agent then randomly selects a batch of memory to update parameters of its Q-value function as approximated by the neural network as set out in `model.py` and as per the Q-learning algorithm\n",
    "    * For the neural network optimization, we use mean-square-error as the loss function; gradients of each parameter of the neural network are backpropagated; and weight of each parameters are updated as per `optim.Adam`\n",
    "    * At every `UPDATE_EVERY steps`, we also update the target Q-value function by performing `soft_update`, which generate an average of target Q-value function and local Q-value function with hyper-parameter `TAU` as the weight\n",
    "    \n",
    "***    \n",
    "The hyper-parameters of the learning algorithm are:\n",
    "* Parameters for the epsilon greedy policy, which are:\n",
    "  * Epsilon at start, epsilon decay rate and min epsilon\n",
    "* Parameters for the agent object, which are:\n",
    "  * Replay buffer size, minibatch size, discount factor, weight for soft update of target parameters, learning rate, and update steps for learning of the network\n",
    "* Parameters for the neural network, which are:\n",
    "  * Architecture of the neural network - in this case, the number of hidden layers and the number of nodes of each hidden layer\n",
    "\n",
    "For tuning the agent to solving the environment which is achieving an average reward per episode of 13 over the trailing 100 episodes). I experimented with the hyper-parameters as opposed to trying additional algorithms.\n",
    "\n",
    "My best result, solving the environemnt in 173 episodes, were achieved with setting:\n",
    "* Epsilon at start = 0.25 , epsilon decay rate = 0.995, min epsilon = 0.001\n",
    "* Replay Buffer size = 1e5, batch size = 128, Gamma = 0.99, Tau = 1e-3, learning rate = 4e-5, update every = 1\n",
    "* Number of hidden layers = 2,  number of nodes of each layer = 64\n",
    "\n",
    "the plots of the various tested parameters in located in the images folder.\n",
    "***\n",
    "### Plot Rewards\n",
    "\n",
    "The plot of rewards per epsiode showing that trained agaent is able to receive an average reward (over 100 episodes) of at least 13.\n",
    "\n",
    "<img src=\"Images/Best_Results.PNG\">\n",
    "\n",
    "***\n",
    "### Ideas for Future Work\n",
    "\n",
    "For future improvements, I will code and test a Double DQN function, and then further to attempt to implement google Dopamine \"https://github.com/google/dopamine\"\n",
    "\n",
    "Additionally, I will work to create and implement convolutional layers to a model in order to read in pixels from the additional pixels challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
